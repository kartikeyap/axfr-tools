#!/usr/bin/env python2.7

import argparse, os, sys
from lib.comparisons import Compare
from lib.db_builder import Builder
from lib.db_purge import Purge
from lib.merger import Merger
from lib.queries import Queries
from lib.nameserverScraper import nScraper
from lib.domainScraper import dScraper
from lib.tldScraper import tScraper

def main(args):
    if args.b:
        build = Builder()
        build.parser()
        build.data_creation()
        build.db_mod()
        sys.exit(0)

    if args.c:
        diff = Compare()
        diff.domains()
        sys.exit(0)

    if args.m:
        bDir = os.getcwd()
        diff = Compare()
        combine = Merger()
        d, f = diff.recurser(bDir)
        combine.digs(d, f)
        sys.exit(0)

    if args.q:
        if args.q[0] == 'domainCount':
            query = Queries('domainCount')
            query.domainCount()
        if args.q[0] == 'nameserverCount':
            query = Queries('nameserverCount')
            query.nameserverCount()
        if args.q[0] == 'nameserverDump':
            query = Queries('nameserverDump')
            query.nameserverDump()
        sys.exit(0)

    if args.p:
        rm = Purge()
        rm.domain()
        sys.exit(0)

    if args.s:
        ## Set the class
        if args.s[0] == 'gwebtools' or args.s[0] == 'whois':
            nServer = raw_input('Which nameserver to query for?\n')
            scrape = nScraper(nServer)
        if args.s[0] == 'robtex':
            dm = raw_input('Which domain to query with?\n')
            scrape = dScraper(dm)
        if args.s[0] == 'domaintyper':
            tld = raw_input('Which TLD to query for?\n')
            scrape = tScraper(tld)

        ## Domain modules
        if args.s[0] == 'robtex':
            scrape.robtex()

        ## Nameserver modules
        if args.s[0] == 'gwebtools':
            scrape.gwebtools()
        if args.s[0] == 'whois':
            scrape.whois()

        ## TLD modules
        if args.s[0] == 'domaintyper':
            scrape.domaintyper()
            for i in scrape.dList:
                print i
            print len(scrape.dList)

        ## EOF
        sys.exit(0)

def menu():
    if len(sys.argv) > 1:
        pass
    else:
        print "The AXFR Toolset"
        print ""
        print "Main Options:"
        print "  Domain List Comparisons: -c"
        print "  Zonefile DB builder:     -b"
        print "  DIG_INFOs Merger:        -m"
        print "  DB query module:         -q"
        print "    domainCount              "
        print "    nameserverCount          "
        print "    nameserverDump           "
        print "  Purge Domains from DB:   -p"
        print "  Scrapers:                -s"
        print "    * Domains                "
        print "        domaintyper          "
        print "        robtex               "
        print "    * Nameservers            "
        print "        gwebtools            "
        print "        whois                "
        print ""
        print "    -h, --help         show the help message and exits"
        sys.exit(0)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='The AXFR Toolset', prog = 'axfr', usage = menu())

    group = parser.add_mutually_exclusive_group(required = True)
    group.add_argument('-b',
        action = 'store_true',
        help = 'Zonefile DB Builder')
    group.add_argument('-c',
        action = 'store_true',
        help = 'Domain List Comparisons')
    group.add_argument('-m',
        action = 'store_true',
        help = 'DIG_INFOs Merger')
    group.add_argument('-q',
        type = str,
        nargs = 1,
        choices = ['domainCount', 'nameserverCount', 'nameserverDump'],
        help = 'DB queries')
    group.add_argument('-p',
        action = 'store_true',
        help = 'Zonefile DB Purger')
    group.add_argument('-s',
        type = str,
        nargs = 1,
        choices = ['domaintyper', 'gwebtools', 'robtex', 'whois'],
        help = 'Scrapers')
    args = parser.parse_args()
    main(args)
